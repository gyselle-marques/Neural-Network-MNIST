{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2UbKpXUBROu8KIX5zlZKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyselle-marques/TransferLearning-DesafioDIO/blob/main/rede_neural_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyT5Sb58bRYm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() #define a conversão de imagem para tensor\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) #carrega parte do treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) #carrega a parte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) #cria um biffer para pegar os dados por partes"
      ],
      "metadata": {
        "id": "3WbW3IUtcXyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "f-d2qr9cfKSG",
        "outputId": "a96cd4a9-8caa-4ae9-c4a5-602af4b0d400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) #verifica as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) #verifica as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj0fpWmGgCOW",
        "outputId": "f224bd39-7d64-4c27-b322-472ab20eaf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
        "        #para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "        def forward(self, X):\n",
        "            X = F.relu(self.linear1(X)) #função de ativação da camada de entrada para a camada interna 1\n",
        "            X = F.relu(self.linear2(X)) #função de ativação da camada interna 1 para a camada interna 2\n",
        "            X = self.linear3(X) #função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "            return F.log_softmax(X, dim=1) #dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "HKfTQtUThWvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #define a política de atualização dos pesos e da bias\n",
        "  inicio = time() #timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() #define o critério para calcular a perda\n",
        "  EPOCHS = 10 #define o número de épocas // númério de epochs que o algoritmo rodará\n",
        "  modelo.train() #ativa o modo de treinamento do modelo\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0 #inicia a perda acumulada da época/epoch em 0\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "      imagens = imagens.view(imagens.shape[0], -1) #converte as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a...\n",
        "      otimizador.zero_grad() #zera os gradientes por conta do ciclo anterior\n",
        "\n",
        "      output = modelo(imagens.to(device)) #coloca os dados no modelo\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) #calcula a perda da epoch em questão\n",
        "\n",
        "      perda_instantanea.backward() #back propagation a partir da perda\n",
        "\n",
        "      otimizador.step() #atualiza os pesos e a bias\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item() #atualização da perda acumulada\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "      print(\"\\nTempo de treino (em minutos) = \",(time()-inicio)/60)\n"
      ],
      "metadata": {
        "id": "9S0UKpMEi28o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens,etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "      # desativa o autograd para acelerar a validação (grafos computacionais dinâmicos possuem custo alto de processamento)\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) #output do modelo em escala logarítmica\n",
        "\n",
        "        ps = torch.exp(logps) #converte o output para escala linear/normal (lembrando que é um tensor)\n",
        "        probab = list(ps.cpu().numpy()[0])\n",
        "        etiqueta_pred = probab.index(max(probab)) #converte o tensor em um número, no caso, o número que o modelo previu como correto\n",
        "        etiqueta_certa = etiquetas.numpy()[i]\n",
        "        if(etiqueta_certa == etiqueta_pred): #compara a previsão com o valor correto\n",
        "          conta_corretas += 1\n",
        "        conta_todas += 1\n",
        "\n",
        "  print(\"Total de imagens testadas = \", conta_todas)\n",
        "  print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "lmhoQZdWlAHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo() #inicializa o modelo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #modelo rodará na GPU se possível\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpwH7zjmmNH_",
        "outputId": "b9a324f1-c69b-490d-ae5c-beea2b9190f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}